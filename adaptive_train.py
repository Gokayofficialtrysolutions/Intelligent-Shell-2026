#!/usr/bin/env python3
# adaptive_train.py
"""
Adaptive Fine-Tuning Script for AGI Terminal Models

This script enables fine-tuning of a base Large Language Model (LLM) using
interaction logs generated by 'interactive_agi.py'. It leverages Parameter-Efficient
Fine-Tuning (PEFT) techniques like LoRA (Low-Rank Adaptation) or QLoRA (Quantized LoRA)
to adapt the model to specific interaction patterns, tool usage, or user queries.

Key Features:
- Parses interaction logs stored in JSONL format (default: ./.agi_terminal_cache/interaction_logs.jsonl).
- Formats interactions into structured prompts suitable for instruction fine-tuning.
  This includes contextual information, user queries, AGI's tool use reasoning,
  tool outcomes, and final AGI responses.
- Supports various data filtering strategies via CLI arguments to select specific
  types of interactions for training (e.g., successful tool use, plan executions).
- Uses Hugging Face Transformers for model loading, training, and PEFT.
- Configurable LoRA/QLoRA parameters (rank, alpha, target modules, etc.).
- Saves the trained PEFT adapters, which can then be merged with the base model
  or loaded dynamically for inference.
- Includes an analysis mode (`--analyze_jsonl_logs`) to inspect log statistics
  and preview formatted training examples without actually starting training.
- Uses 'rich' library for enhanced terminal output and progress bars if available.

Workflow:
1. Load interaction logs from the specified JSONL file.
2. Filter interactions based on CLI arguments (if any).
3. Format the selected interactions into training examples (prompt-completion pairs).
4. Load the base LLM and tokenizer.
5. Configure PEFT (LoRA/QLoRA) and apply it to the base model.
6. Train the model using the prepared dataset.
7. Save the trained PEFT adapters and tokenizer configuration to the specified output directory.

This script is designed to help improve the AGI's performance and tailor its behavior
based on real-world usage patterns.
"""

import argparse
import os
import glob
import random
from pathlib import Path
import json
import re
from datetime import datetime, timedelta

try:
    from rich.console import Console
    from rich.progress import Progress, BarColumn, TextColumn, TimeElapsedColumn, TimeRemainingColumn
    from rich.text import Text
    from rich.table import Table
    RICH_AVAILABLE = True
    console = Console()
except ImportError:
    RICH_AVAILABLE = False
    class Console:
        def print(self, *args, **kwargs): print(*args)
    console = Console()
    console.print("[yellow]WARNING: Rich library not found. Install with `pip install rich`[/yellow]")

import torch
from transformers import (
    AutoModelForCausalLM, AutoTokenizer, TrainingArguments, Trainer,
    DataCollatorForLanguageModeling, BitsAndBytesConfig
)
from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training, TaskType

DEFAULT_MODEL_PATH = "./merged_model"
DEFAULT_OUTPUT_DIR = "./merged_model_adapters"  # Default directory to save trained LoRA adapters

def parse_arguments():
    """Parses command-line arguments for the training script."""
    parser = argparse.ArgumentParser(
        description="Adaptive fine-tuning script for AGI model using JSONL interaction logs.",
        formatter_class=argparse.ArgumentDefaultsHelpFormatter # Show default values in help
    )

    # --- Core Arguments ---
    parser.add_argument(
        "--model_path", type=str, default=DEFAULT_MODEL_PATH,
        help="Path to the base Hugging Face model directory (e.g., './merged_model')."
    )
    parser.add_argument(
        "--jsonl_log_path", type=str,
        default=str(Path(__file__).resolve().parent / ".agi_terminal_cache" / "interaction_logs.jsonl"),
        help="Path to the JSONL file containing interaction logs."
    )
    parser.add_argument(
        "--output_dir", type=str, default=DEFAULT_OUTPUT_DIR,
        help="Directory where the trained PEFT adapters (and tokenizer config) will be saved."
    )

    # --- Analysis Mode ---
    parser.add_argument(
        "--analyze_jsonl_logs", nargs='?', const=-1, type=int, metavar='N',
        help="If specified, analyzes the JSONL logs, prints statistics, and optionally shows N "
             "random formatted training examples. No training will be performed. "
             "If N is omitted, defaults to showing a few examples (e.g., 5)."
    )

    # --- Training Hyperparameters ---
    g_train = parser.add_argument_group('Training Hyperparameters')
    g_train.add_argument("--num_train_epochs", type=int, default=1, help="Number of training epochs.")
    g_train.add_argument("--per_device_train_batch_size", type=int, default=1, help="Batch size per device during training.")
    g_train.add_argument("--gradient_accumulation_steps", type=int, default=4, help="Number of steps to accumulate gradients before updating weights.")
    g_train.add_argument("--learning_rate", type=float, default=2e-4, help="Initial learning rate for the optimizer.")
    g_train.add_argument("--max_seq_length", type=int, default=1024, help="Maximum sequence length for tokenization. Longer sequences will be truncated.")
    g_train.add_argument("--optimizer", type=str, default="adamw_torch", help="Optimizer to use (e.g., 'adamw_torch', 'paged_adamw_8bit').")
    g_train.add_argument("--lr_scheduler_type", type=str, default="linear", help="Learning rate scheduler type (e.g., 'linear', 'cosine').")
    g_train.add_argument("--warmup_steps", type=int, default=0, help="Number of warmup steps for the learning rate scheduler.")
    g_train.add_argument("--weight_decay", type=float, default=0.0, help="Weight decay applied to layers (if supported by optimizer).")

    # --- PEFT/LoRA Specific Arguments ---
    g_lora = parser.add_argument_group('PEFT/LoRA Configuration')
    g_lora.add_argument("--lora_r", type=int, default=16, help="LoRA attention dimension (rank).")
    g_lora.add_argument("--lora_alpha", type=int, default=32, help="LoRA alpha parameter (scaling factor).")
    g_lora.add_argument("--lora_dropout", type=float, default=0.05, help="Dropout probability for LoRA layers.")
    g_lora.add_argument(
        "--lora_target_modules", type=str,
        default="q_proj,v_proj,k_proj,o_proj,gate_proj,up_proj,down_proj", # Common for Llama-like models
        help="Comma-separated list of module names to target with LoRA (e.g., 'q_proj,v_proj'). Exact names depend on the model architecture."
    )
    g_lora.add_argument(
        "--use_qlora", action="store_true",
        help="Enable QLoRA: 4-bit quantization of the base model with LoRA fine-tuning. Reduces memory usage significantly but may impact performance or speed."
    )

    # --- Data Filtering/Strategy Arguments ---
    g_data = parser.add_argument_group('Data Filtering and Strategy')
    g_data.add_argument(
        "--train-on-successful-tool-use", type=str, default=None, metavar="TOOL_NAME|all",
        help="Filter training data to include only turns with successful use of a specific tool (e.g., 'run_shell') or 'all' successful tool uses."
    )
    g_data.add_argument(
        "--train-on-failed-tool-use", type=str, default=None, metavar="TOOL_NAME|all",
        help="Filter for turns with failed, cancelled, or system-denied tool use (specific tool or 'all')."
    )
    g_data.add_argument(
        "--train-on-successful-plans", action="store_true",
        help="Filter for turns involving successfully completed multi-step plans (i.e., 'execute_plan' not halted)."
    )
    g_data.add_argument(
        "--train-on-halted-plans", action="store_true",
        help="Filter for turns where a multi-step plan ('execute_plan') was halted due to step failure or cancellation."
    )
    g_data.add_argument(
        "--min-tool-interactions", type=int, default=0, metavar="N",
        help="Filter for turns that involved at least N tool interactions (either single calls or steps within a plan)."
    )

    return parser.parse_args()

def format_context_for_prompt(context_dict: dict) -> str:
    """
    Formats the context dictionary (from interaction logs) into a string
    suitable for inclusion in the training prompt.
    """
    if not context_dict: return "SYSTEM_CONTEXT: None" # Should ideally not happen if logs are consistent
    parts = []
    if "cwd" in context_dict: parts.append(f"CWD: {context_dict['cwd']}")
    if "project_root" in context_dict: parts.append(f"ProjectRoot: {context_dict['project_root']}")

    git_info = context_dict.get("git_info", {})
    if git_info.get("in_git_repo"):
        branch = git_info.get('branch', 'N/A')
        modified_files_count = git_info.get('modified_files', 0)
        # Provide a more descriptive status than just count
        git_status_description = f"{modified_files_count} modified files" if modified_files_count > 0 else "Clean working directory"
        parts.append(f"Git: Branch='{branch}', Status='{git_status_description}'")

    file_counts = context_dict.get("file_type_counts", {})
    if file_counts:
        # Sort by count, then by name for consistent ordering if counts are equal
        sorted_file_counts = sorted(file_counts.items(), key=lambda item: (-item[1], item[0]))
        top_files = sorted_file_counts[:3] # Show top 3 most common relevant file types
        files_str = ", ".join([f"{lang}:{count}" for lang, count in top_files])
        if len(file_counts) > 3:
            files_str += ", ..." # Indicate more file types exist but are not listed
        parts.append(f"FileTypesPresent: {files_str}")

    key_snippets_headers = context_dict.get("key_file_snippets", [])
    if key_snippets_headers:
        # Extract just the filenames from the snippet headers for brevity in this context string
        filenames_from_snippets = []
        for header_text_or_snippet_obj in key_snippets_headers: # Snippets might be full text or just headers
            if isinstance(header_text_or_snippet_obj, str): # If it's the header line
                 match = re.search(r"--- Snippet from ([\w\.\-]+)", header_text_or_snippet_obj)
                 if match: filenames_from_snippets.append(match.group(1))
            # If snippets are objects, this needs adjustment based on their structure
        if filenames_from_snippets:
            parts.append(f"KeyFileSnippetsProvidedFor: [{', '.join(sorted(list(set(filenames_from_snippets))))}]") # Sort for consistency

    # Construct the final context string
    if parts:
        return "SYSTEM_CONTEXT:\n" + "\n".join(f"  - {p}" for p in parts)
    else:
        return "SYSTEM_CONTEXT: (No specific context details were logged for this turn)"


def format_tool_interactions_for_prompt(tool_interactions: list, max_outcome_chars: int = 200) -> str:
    """
    Formats a list of tool interaction dictionaries into a structured string
    for inclusion in training prompts, showing the sequence of tool calls and outcomes.
    """
    if not tool_interactions: return "" # Return empty if no tool interactions

    # This dialogue will represent the AGI's thought process and system's responses related to tools
    dialogue_parts = ["\nINTERMEDIATE_TOOL_STEPS_AND_OUTCOMES:"]

    for i, tool_call_log_entry in enumerate(tool_interactions):
        action_type = tool_call_log_entry.get('action_type', 'unknown_action')
        action_details = tool_call_log_entry.get('action_details', {}) # This is the JSON AGI proposed
        reasoning_by_agi = tool_call_log_entry.get('reasoning', 'No reasoning provided by AGI.')
        system_outcome_summary = tool_call_log_entry.get('tool_outcome_summary', 'No outcome summary logged.')
        # This is the AGI's response *after* seeing the tool outcome, if it was a single tool call that re-prompted.
        # For plans, this might be None until the final summary.
        agi_response_to_tool_outcome = tool_call_log_entry.get('agi_secondary_raw_response')

        dialogue_parts.append(f"  --- TOOL_INTERACTION_{i+1} ---")
        dialogue_parts.append(f"    AGI_PROPOSED_ACTION_TYPE: {action_type}")

        # Summarize action details to avoid overly long prompts
        action_details_summary_str = json.dumps(action_details)
        if len(action_details_summary_str) > 150: # Truncate if too long
            action_details_summary_str = action_details_summary_str[:147] + "..."
        dialogue_parts.append(f"    AGI_PROPOSED_ACTION_DETAILS: {action_details_summary_str}")
        dialogue_parts.append(f"    AGI_REASONING_FOR_ACTION: {reasoning_by_agi}")

        # Summarize system outcome
        outcome_display = system_outcome_summary
        if len(outcome_display) > max_outcome_chars:
            outcome_display = outcome_display[:max_outcome_chars - 3] + "..." # Account for "..."
        dialogue_parts.append(f"    SYSTEM_RESPONSE_TO_ACTION: {outcome_display}")

        if agi_response_to_tool_outcome: # If AGI had a follow-up response to this specific tool outcome
            secondary_resp_display = agi_response_to_tool_outcome
            if len(secondary_resp_display) > max_outcome_chars * 1.5: # Allow slightly more for AGI's own text
                secondary_resp_display = secondary_resp_display[:int(max_outcome_chars * 1.5) - 3] + "..."
            dialogue_parts.append(f"    AGI_SUBSEQUENT_THOUGHT_OR_RESPONSE: {secondary_resp_display}")

    return "\n".join(dialogue_parts)

def _format_for_direct_answer(entry: dict, eos_token: str) -> Optional[str]:
    """Formats an interaction where AGI directly answers without tools."""
    user_query = entry.get("user_query", "")
    agi_final_response = entry.get("agi_final_response_to_user", "")
    context_dict = entry.get("context_at_query_time", {})

    if not user_query or not agi_final_response: return None # Essential fields missing

    context_str = format_context_for_prompt(context_dict)
    # Simple instruction for direct Q&A
    system_instruction = "SYSTEM_INSTRUCTION: Provide a direct and helpful answer to the user's query."

    return f"{context_str}\n{system_instruction}\nUSER: {user_query}\nASSISTANT: {agi_final_response}{eos_token}"

def _format_for_single_tool_call_generation(entry: dict, eos_token: str) -> Optional[str]:
    """
    Formats an interaction where the AGI's first response is to propose a single tool call.
    Trains the AGI to generate the JSON for that tool call.
    """
    user_query = entry.get("user_query", "")
    # This is the AGI's JSON proposal for the tool
    agi_initial_tool_proposal_json = entry.get("agi_initial_raw_response", "")
    context_dict = entry.get("context_at_query_time", {})

    if not user_query or not agi_initial_tool_proposal_json: return None
    # Validate that the initial response is indeed a JSON for a single tool (not a plan)
    try:
        parsed_json = json.loads(agi_initial_tool_proposal_json.strip())
        if not isinstance(parsed_json, dict) or not parsed_json.get("action") or parsed_json.get("action") == "execute_plan":
            return None # Not a single tool call JSON
    except json.JSONDecodeError:
        return None # Not JSON

    context_str = format_context_for_prompt(context_dict)
    # Instruction guiding AGI to consider tools
    system_instruction = (
        "SYSTEM_INSTRUCTION: You have access to tools (run_shell, read_file, write_file, web_search, git operations, execute_python_code, execute_plan). "
        "If a tool is appropriate for the user's query, respond with a JSON object specifying the action and parameters. "
        "Otherwise, answer directly."
    )

    return f"{context_str}\n{system_instruction}\nUSER: {user_query}\nASSISTANT: {agi_initial_tool_proposal_json.strip()}{eos_token}"


def _format_for_tool_outcome_processing(entry: dict, tool_interaction: dict, eos_token: str) -> Optional[str]:
    """
    Formats an interaction where AGI processes the outcome of a single tool call
    and then generates its final response to the user.
    """
    user_query = entry.get("user_query", "")
    context_dict = entry.get("context_at_query_time", {})
    # This is the AGI's textual response *after* seeing the tool outcome
    agi_response_after_tool_outcome = tool_interaction.get("agi_secondary_raw_response")

    if not user_query or not agi_response_after_tool_outcome or not context_dict: return None

    context_str = format_context_for_prompt(context_dict)
    # tool_interaction should be a single entry from the entry["tool_interactions"] list
    tool_outcome_summary_str = format_tool_interactions_for_prompt([tool_interaction]) # Format just this one

    system_instruction = "SYSTEM_INSTRUCTION: Based on the outcome of the previous tool action, provide a comprehensive answer or take the next appropriate step."

    return f"{context_str}\nUSER: {user_query}{tool_outcome_summary_str}\n{system_instruction}\nASSISTANT: {agi_response_after_tool_outcome}{eos_token}"


def _format_for_plan_generation(entry: dict, eos_token: str) -> Optional[str]:
    """
    Formats an interaction where AGI's first response is to propose a multi-step plan.
    Trains the AGI to generate the JSON for the 'execute_plan' action.
    """
    user_query = entry.get("user_query", "")
    # This is the AGI's JSON proposal for the 'execute_plan'
    agi_initial_plan_proposal_json = entry.get("agi_initial_raw_response", "")
    context_dict = entry.get("context_at_query_time", {})

    if not user_query or not agi_initial_plan_proposal_json: return None
    # Validate that the initial response is an 'execute_plan' JSON
    try:
        parsed_json = json.loads(agi_initial_plan_proposal_json.strip())
        if not isinstance(parsed_json, dict) or parsed_json.get("action") != "execute_plan":
            return None
    except json.JSONDecodeError:
        return None

    context_str = format_context_for_prompt(context_dict)
    system_instruction = (
        "SYSTEM_INSTRUCTION: For complex, multi-step tasks, use the 'execute_plan' action. "
        "Define a sequence of tool calls within the 'steps' array of the plan JSON."
    )

    return f"{context_str}\n{system_instruction}\nUSER: {user_query}\nASSISTANT: {agi_initial_plan_proposal_json.strip()}{eos_token}"


def _format_for_plan_summary(entry: dict, eos_token: str) -> Optional[str]:
    """
    Formats an interaction where AGI responds after a multi-step plan has been executed (or halted).
    Trains AGI to summarize plan outcome and provide final response to user.
    """
    user_query = entry.get("user_query", "")
    context_dict = entry.get("context_at_query_time", {})
    plan_details_from_log = entry.get("plan_execution_details", {})
    # The AGI's initial JSON for the plan proposal
    agi_initial_plan_json = entry.get("agi_initial_raw_response", "")
    # The AGI's final textual response after the plan execution summary
    final_response_after_plan_execution = plan_details_from_log.get("agi_final_response_after_plan")

    if not all([user_query, context_dict, plan_details_from_log, final_response_after_plan_execution, agi_initial_plan_json]):
        return None

    context_str = format_context_for_prompt(context_dict)

    # Construct a summary of the plan's execution from individual tool interactions
    plan_step_outcome_summaries = []
    for tool_interaction_log in entry.get("tool_interactions", []):
        # Check if this tool interaction was part of the plan being summarized
        if tool_interaction_log.get("part_of_plan_step") is not None: # Ensure it's a plan step
            action_type = tool_interaction_log.get('action_type', 'unknown_action')
            outcome_text = tool_interaction_log.get('tool_outcome_summary', 'No outcome logged.')
            # Truncate individual step outcomes for brevity in the summary prompt
            truncated_outcome = outcome_text[:150] + ("..." if len(outcome_text) > 150 else "")
            plan_step_outcome_summaries.append(
                f"  - Step {tool_interaction_log['part_of_plan_step'] + 1} (Action: {action_type}): {truncated_outcome}"
            )

    plan_execution_summary_for_prompt = "PLAN_EXECUTION_SUMMARY:\n" + "\n".join(plan_step_outcome_summaries) \
        if plan_step_outcome_summaries else "PLAN_EXECUTION_SUMMARY: No detailed step outcomes available or plan was not executed."

    # Include the AGI's originally proposed plan for context
    proposed_plan_json_for_prompt = f"ORIGINALLY_PROPOSED_PLAN_JSON:\n{agi_initial_plan_json.strip()}"

    system_instruction = "SYSTEM_INSTRUCTION: Review the summary of the executed plan and its step outcomes. Provide a final, comprehensive response to the user based on this information."

    return (
        f"{context_str}\n"
        f"{proposed_plan_json_for_prompt}\n" # AGI sees what it originally planned
        f"{plan_execution_summary_for_prompt}\n" # AGI sees what actually happened
        f"{system_instruction}\n"
        f"USER_QUERY_CONTEXT: {user_query}\n" # Remind AGI of original query
        f"ASSISTANT: {final_response_after_plan_execution}{eos_token}"
    )


def format_interaction_for_training(interaction_entry: dict, tokenizer_eos_token: str) -> list[str]:
    """
    Converts a single interaction log entry into one or more formatted training examples.
    It tries to create examples for:
    1. AGI generating a tool call (if applicable).
    2. AGI processing a tool call's outcome (if applicable).
    3. AGI generating a plan (if applicable).
    4. AGI processing a plan's outcome (if applicable).
    5. AGI giving a direct answer (if no tools/plans or as a fallback).
    """
    training_examples = []
    user_query = interaction_entry.get("user_query")
    agi_final_response = interaction_entry.get("agi_final_response_to_user")

    # Ensure basic fields are present for any example generation
    if not user_query: return [] # Cannot form an example without user query

    is_plan_turn = "plan_execution_details" in interaction_entry and \
                   interaction_entry["plan_execution_details"].get("action_type") == "execute_plan"
    tool_interactions = interaction_entry.get("tool_interactions", [])

    # Try to format for plan generation and/or plan summary
    if is_plan_turn:
        ex_plan_gen = _format_for_plan_generation(interaction_entry, tokenizer_eos_token)
        if ex_plan_gen: training_examples.append(ex_plan_gen)

        # A plan always has a summary/final response phase
        ex_plan_sum = _format_for_plan_summary(interaction_entry, tokenizer_eos_token)
        if ex_plan_sum: training_examples.append(ex_plan_sum)

    # Try to format for single tool call generation and/or outcome processing
    elif tool_interactions: # Single tool call (or sequence not explicitly a "plan")
        # Example for generating the first tool call proposal
        # Check if the AGI's initial response was a JSON for a single tool
        agi_initial_raw_response = interaction_entry.get("agi_initial_raw_response", "")
        try:
            parsed_initial_json = json.loads(agi_initial_raw_response.strip())
            if isinstance(parsed_initial_json, dict) and parsed_initial_json.get("action") and \
               parsed_initial_json.get("action") != "execute_plan":
                ex_single_tool_gen = _format_for_single_tool_call_generation(interaction_entry, tokenizer_eos_token)
                if ex_single_tool_gen: training_examples.append(ex_single_tool_gen)
        except json.JSONDecodeError:
            pass # Initial response was not JSON, so not a tool proposal generation step

        # Example for processing the outcome of the first tool call (if it had a secondary AGI response)
        # This assumes the first tool interaction is the primary one for this turn if not a plan.
        first_tool_interaction = tool_interactions[0]
        if first_tool_interaction.get("agi_secondary_raw_response"):
            ex_tool_outcome_proc = _format_for_tool_outcome_processing(interaction_entry, first_tool_interaction, tokenizer_eos_token)
            if ex_tool_outcome_proc: training_examples.append(ex_tool_outcome_proc)
        elif not training_examples and agi_final_response: # If no tool gen/proc example, but there's a final response
            # This could be a case where tool use failed and AGI responded directly, or tool outcome didn't need secondary AGI step.
            # Fallback to direct answer format using the final response.
            ex_direct = _format_for_direct_answer(interaction_entry, tokenizer_eos_token)
            if ex_direct: training_examples.append(ex_direct)

    # If no tool/plan examples were generated, but there's a final AGI response, format as direct answer
    else: # No plan, no tool interactions
        if agi_final_response: # Must have a final response to be a valid direct answer example
            ex_direct = _format_for_direct_answer(interaction_entry, tokenizer_eos_token)
            if ex_direct: training_examples.append(ex_direct)

    return training_examples


def load_raw_interaction_logs(jsonl_log_path: str) -> list[dict]:
    """Loads all interaction entries from a JSONL log file."""
    raw_interactions = []
    log_file = Path(jsonl_log_path)
    if not log_file.exists():
        console.print(f"[yellow]Warning: JSONL log file not found at '{jsonl_log_path}'. Returning empty list.[/yellow]")
        return []

    console.print(f"[info]Processing JSONL log file: {jsonl_log_path}...[/info]")
    try:
        with open(log_file, 'r', encoding='utf-8') as f:
            for line_num, line in enumerate(f, 1):
                try:
                    interaction_entry = json.loads(line)
                    raw_interactions.append(interaction_entry)
                except json.JSONDecodeError as e:
                    console.print(f"[yellow]Skipping malformed JSON line {line_num} in '{jsonl_log_path}': {e}[/yellow]")
    except Exception as e:
        console.print(f"[error]Critical error reading log file '{jsonl_log_path}': {e}[/error]")
        return [] # Return empty on critical read error

    if not raw_interactions:
        console.print(f"[yellow]No valid interaction entries found in '{jsonl_log_path}'.[/yellow]")
    return raw_interactions


def _is_tool_call_successful(tool_call: dict) -> bool:
    """
    Determines if a logged tool call was successful based on user confirmation and outcome summary.
    Considers system denials and malformed requests as failures.
    """
    user_confirmation = tool_call.get("user_confirmation", "").lower()
    # Explicit failures or cancellations by user/system
    if user_confirmation in ["cancelled", "denied_by_system_whitelist",
                             "n/a_malformed_request", "denied_by_system_static_analysis"]:
        return False

    outcome_summary = tool_call.get("tool_outcome_summary", "").lower()
    # Keywords indicating failure in the outcome summary
    failure_keywords = ["error:", "failed", "malformed", "exception:", "denied", "invalid"]
    if any(err_kw in outcome_summary for err_kw in failure_keywords):
        return False

    # Keywords indicating success (can be expanded)
    success_keywords = ["success", "processed", "executed", "identical", "up-to-date",
                        "no output or exception", "nothing to commit", "provided to agi",
                        "file read successfully", "file written successfully"] # Added more specific success phrases
    if any(succ_kw in outcome_summary for succ_kw in success_keywords):
        return True

    # Specific case for execute_python_code: success if no "exception:" and not cancelled/denied
    if tool_call.get("action_type") == "execute_python_code" and \
       "exception:" not in outcome_summary and \
       user_confirmation not in ["cancelled", "denied_by_system_static_analysis"]:
        return True

    # Default to False if no clear success/failure indicators are met
    # This is safer than assuming success.
    return False


def filter_raw_interactions(raw_interactions: list[dict], args: argparse.Namespace) -> list[dict]:
    """
    Filters the raw list of interaction log entries based on criteria specified in CLI arguments.
    This allows for targeted training on specific types of interactions.
    """
    # If no filter arguments are provided, return all interactions
    if not any([args.train_on_successful_tool_use,
                args.train_on_failed_tool_use,
                args.train_on_successful_plans,
                args.train_on_halted_plans,
                args.min_tool_interactions > 0]):
        return raw_interactions # No filters applied

    filtered_interactions = []
    console.print("[info]Applying training data filters based on CLI arguments...")

    for entry in raw_interactions:
        passes_current_entry = True # Assume it passes until a filter criterion fails it

        # --- Plan-based Filters ---
        is_plan_turn = "plan_execution_details" in entry
        plan_details = entry.get("plan_execution_details", {})
        plan_outcome = plan_details.get("plan_outcome", "") # e.g., "Completed", "Halted at step X", "Malformed"

        if args.train_on_successful_plans:
            # A plan is successful if it's a plan turn and its outcome doesn't indicate halting or malformation
            if not (is_plan_turn and "Halted" not in plan_outcome and "Malformed" not in plan_outcome):
                passes_current_entry = False

        if args.train_on_halted_plans and passes_current_entry: # Only apply if still passing
            if not (is_plan_turn and "Halted" in plan_outcome):
                passes_current_entry = False

        # --- Tool Interaction Count Filter ---
        tool_interactions_list = entry.get("tool_interactions", [])
        num_tool_interactions_in_turn = len(tool_interactions_list)
        if args.min_tool_interactions > 0 and num_tool_interactions_in_turn < args.min_tool_interactions:
            passes_current_entry = False

        # --- Specific Tool Use Filters (Success/Failure) ---
        # These filters check if *any* tool call within the turn matches the criteria.
        if passes_current_entry and (args.train_on_successful_tool_use or args.train_on_failed_tool_use):
            found_matching_tool_call = False
            for tool_call in tool_interactions_list:
                tool_action_type = tool_call.get("action_type")
                tool_was_successful = _is_tool_call_successful(tool_call)

                # Check for successful tool use filter
                if args.train_on_successful_tool_use and tool_was_successful:
                    if args.train_on_successful_tool_use == "all" or args.train_on_successful_tool_use == tool_action_type:
                        found_matching_tool_call = True
                        break # Found a match for this entry, no need to check other tools in this turn

                # Check for failed tool use filter (if not already matched by success)
                if not found_matching_tool_call and args.train_on_failed_tool_use and not tool_was_successful:
                    if args.train_on_failed_tool_use == "all" or args.train_on_failed_tool_use == tool_action_type:
                        found_matching_tool_call = True
                        break

            if not found_matching_tool_call: # If after checking all tools, no match for the active filter
                passes_current_entry = False

        # If the entry passed all applicable filters, add it
        if passes_current_entry:
            filtered_interactions.append(entry)

    console.print(f"[info]Retained {len(filtered_interactions)} interactions after filtering (out of {len(raw_interactions)} original).")
    return filtered_interactions


def prepare_training_dataset(args: argparse.Namespace, tokenizer: AutoTokenizer) -> list[dict]:
    """
    Loads, filters, and formats interaction logs into a tokenized dataset ready for training.

    Returns:
        A list of dictionaries, where each dictionary contains 'input_ids',
        'attention_mask', and 'labels' suitable for the Hugging Face Trainer.
        Returns an empty list if no data can be prepared.
    """
    raw_interactions = load_raw_interaction_logs(args.jsonl_log_path)
    if not raw_interactions:
        console.print("[warning]No raw interaction logs loaded. Cannot prepare dataset.[/warning]")
        return []

    filtered_interactions = filter_raw_interactions(raw_interactions, args)
    if not filtered_interactions:
        console.print("[warning]No interactions remained after filtering. Cannot prepare dataset.[/warning]")
        return []

    all_formatted_training_texts = []
    console.print(f"[info]Formatting {len(filtered_interactions)} filtered interactions into training examples...[/info]")

    # Setup Rich progress bar if available
    progress_context = None
    if RICH_AVAILABLE:
        progress_context = Progress(
            TextColumn("[progress.description]{task.description}"),
            BarColumn(), TextColumn("[progress.percentage]{task.percentage:>3.1f}%"),
            TimeElapsedColumn(), TextColumn("Processed: {task.completed}/{task.total}"),
            console=console, transient=False # Keep it visible after completion
        )
        formatting_task = progress_context.add_task("Formatting logs", total=len(filtered_interactions))
        progress_context.start()

    for entry in filtered_interactions:
        formatted_texts_for_this_entry = format_interaction_for_training(entry, tokenizer.eos_token)
        if formatted_texts_for_this_entry:
            all_formatted_training_texts.extend(formatted_texts_for_this_entry)
        if RICH_AVAILABLE and progress_context:
            progress_context.update(formatting_task, advance=1)

    if RICH_AVAILABLE and progress_context:
        progress_context.stop()
        console.print(f"[info]Log formatting complete. Generated {len(all_formatted_training_texts)} potential training strings.")

    if not all_formatted_training_texts:
        console.print("[yellow]No training examples could be generated from the filtered logs.[/yellow]")
        return []

    # Basic check for minimum dataset size before proceeding to tokenization
    min_effective_examples = 5  # Arbitrary small number; adjust as needed
    if len(all_formatted_training_texts) < min_effective_examples:
        console.print(
            f"[warning]Number of generated training strings ({len(all_formatted_training_texts)}) "
            f"is less than the recommended minimum of {min_effective_examples}. "
            "Training with very few examples might be ineffective or lead to overfitting."
        )
        if not get_user_confirmation(
            f"Proceed with only {len(all_formatted_training_texts)} training strings?",
            default_to_yes_in_non_interactive=False # Default to NO in CI for tiny datasets
        ):
            console.print("[info]Training aborted by user due to small dataset size.[/info]")
            return []

    console.print(f"[success]Successfully generated {len(all_formatted_training_texts)} training strings from logs.[/success]")
    console.print(f"[info]Tokenizing {len(all_formatted_training_texts)} training strings (max_seq_length: {args.max_seq_length})...[/info]")

    tokenized_dataset_for_trainer = []

    if RICH_AVAILABLE:
        progress_context = Progress(
            TextColumn("[progress.description]{task.description}"), BarColumn(),
            TextColumn("[progress.percentage]{task.percentage:>3.1f}%"),
            TimeElapsedColumn(), TextColumn("Tokenized: {task.completed}/{task.total}"),
            console=console, transient=False
        )
        tokenization_task = progress_context.add_task("Tokenizing data", total=len(all_formatted_training_texts))
        progress_context.start()

    for text_example in all_formatted_training_texts:
        # Tokenize each formatted string.
        # `padding="max_length"` ensures all sequences are padded to `max_seq_length`.
        # `truncation=True` ensures sequences longer than `max_seq_length` are cut.
        tokenized_input = tokenizer(
            text_example,
            truncation=True,
            max_length=args.max_seq_length,
            padding="max_length" # Pad to max_length for consistent tensor shapes
        )
        # For language modeling, labels are typically the same as input_ids.
        # The model itself handles shifting for causal language modeling.
        tokenized_dataset_for_trainer.append({
            "input_ids": tokenized_input["input_ids"],
            "attention_mask": tokenized_input["attention_mask"],
            "labels": tokenized_input["input_ids"].copy() # Important: copy labels
        })
        if RICH_AVAILABLE and progress_context:
            progress_context.update(tokenization_task, advance=1)

    if RICH_AVAILABLE and progress_context:
        progress_context.stop()
        console.print(f"[info]Tokenization complete.")

    if not tokenized_dataset_for_trainer:
        console.print("[yellow]Tokenization resulted in an empty dataset. This should not happen if there were input strings.[/yellow]")
        return []

    console.print(f"[success]Successfully tokenized {len(tokenized_dataset_for_trainer)} examples for training.[/success]")
    return tokenized_dataset_for_trainer


def analyze_and_print_stats(
    raw_interactions: list[dict],
    num_examples_to_print: int,
    tokenizer_eos_for_examples: str,
    args_for_filtering: Optional[argparse.Namespace] = None # Pass CLI args to allow filtering before analysis
    ):
    """
    Analyzes interaction logs, prints statistics, and optionally displays
    a sample of formatted training examples.
    If args_for_filtering is provided, logs are filtered before analysis.
    """
    if not raw_interactions:
        console.print("[yellow]No interaction logs loaded to analyze.[/yellow]")
        return

    interactions_to_analyze = raw_interactions
    analysis_title_suffix = "(Full Log)"
    if args_for_filtering: # If CLI args provided, filter before analyzing (to see effect of filters)
        console.print("[info]Analyzing logs based on provided filter arguments for preview...")
        interactions_to_analyze = filter_raw_interactions(raw_interactions, args_for_filtering)
        analysis_title_suffix = "(Filtered Log)"
        if not interactions_to_analyze:
            console.print("[yellow]No interactions remain after filtering. Cannot perform detailed analysis on filtered set.[/yellow]")
            # Optionally, one could fall back to showing stats for raw_interactions or just stop.
            # For now, let's indicate that filtering resulted in zero.
            return


    total_turns = len(interactions_to_analyze)
    turns_with_any_tool_use = 0
    tool_action_type_counts = {} # Counts for each action_type (e.g., run_shell: 5, read_file: 3)
    tool_call_outcomes = {}    # Nested dict: {action_type: {success: N, error: M, cancelled: K, other: L}}

    total_user_query_chars = 0
    total_agi_final_response_chars = 0

    turns_with_plans = 0
    successful_completed_plans = 0 # Plans that ran to completion without explicit halt
    halted_plans_count = 0         # Plans explicitly logged as "Halted"

    for entry in interactions_to_analyze:
        total_user_query_chars += len(entry.get("user_query", ""))
        total_agi_final_response_chars += len(entry.get("agi_final_response_to_user", ""))

        # Plan statistics
        if "plan_execution_details" in entry:
            turns_with_plans += 1
            plan_outcome_str = entry["plan_execution_details"].get("plan_outcome", "").lower()
            if "halted" in plan_outcome_str:
                halted_plans_count += 1
            elif "completed" in plan_outcome_str or ("attempted" in plan_outcome_str and "halted" not in plan_outcome_str): # Consider "all steps attempted" as completed for this stat
                successful_completed_plans += 1

        # Tool interaction statistics (for individual tool calls, including those within plans)
        tool_interactions_list_for_entry = entry.get("tool_interactions", [])
        if tool_interactions_list_for_entry:
            turns_with_any_tool_use += 1
            for tool_call_log in tool_interactions_list_for_entry:
                action = tool_call_log.get("action_type", "unknown_action")
                tool_action_type_counts[action] = tool_action_type_counts.get(action, 0) + 1

                # Initialize outcome counts for this action type if not present
                if action not in tool_call_outcomes:
                    tool_call_outcomes[action] = {"success": 0, "error_or_rejection": 0, "cancelled_by_user": 0, "other_or_unknown": 0}

                # Determine outcome category
                if _is_tool_call_successful(tool_call_log):
                    tool_call_outcomes[action]["success"] += 1
                elif tool_call_log.get("user_confirmation", "").lower() == "cancelled":
                    tool_call_outcomes[action]["cancelled_by_user"] +=1
                elif tool_call_log.get("user_confirmation", "").lower() in [
                    "denied_by_system_whitelist", "n/a_malformed_request",
                    "denied_by_system_static_analysis", "n/a_unknown_action"]:
                    tool_call_outcomes[action]["error_or_rejection"] += 1
                elif "error:" in tool_call_log.get("tool_outcome_summary", "").lower() or \
                     "failed" in tool_call_log.get("tool_outcome_summary", "").lower() or \
                     "exception:" in tool_call_log.get("tool_outcome_summary", "").lower():
                    tool_call_outcomes[action]["error_or_rejection"] += 1
                else:
                    tool_call_outcomes[action]["other_or_unknown"] += 1

    console.print(f"\n[bold underline]Interaction Log Analysis {analysis_title_suffix}[/bold underline]")
    if total_turns == 0:
        console.print("[yellow]No interaction entries to analyze in the selected set.[/yellow]")
        return

    console.print(f"Total Interaction Turns Analyzed: {total_turns}")
    console.print(f"Turns with any Tool Use (single or plan steps): {turns_with_any_tool_use} ({turns_with_any_tool_use/total_turns:.1%} if total_turns > 0 else '0.0%'})")
    console.print(f"Turns involving an 'execute_plan' action: {turns_with_plans} ({turns_with_plans/total_turns:.1%} if total_turns > 0 else '0.0%'})")
    if turns_with_plans > 0 :
        console.print(f"  - Successfully Completed Plans (not halted): {successful_completed_plans}")
        console.print(f"  - Halted Plans: {halted_plans_count}")

    avg_user_query_chars_val = total_user_query_chars / total_turns if total_turns > 0 else 0
    avg_agi_response_chars_val = total_agi_final_response_chars / total_turns if total_turns > 0 else 0
    console.print(f"Average User Query Length: {avg_user_query_chars_val:.0f} chars")
    console.print(f"Average AGI Final Response Length: {avg_agi_response_chars_val:.0f} chars")

    if tool_action_type_counts:
        console.print("\n[bold]Tool Usage Breakdown (Counts of Individual Tool Calls):[/bold]")
        tool_usage_table = Table(title="Tool Call Counts by Action Type")
        tool_usage_table.add_column("Tool Action Type", style="cyan", overflow="fold")
        tool_usage_table.add_column("Number of Calls", style="magenta", justify="right")
        for tool_type, count in sorted(tool_action_type_counts.items()):
            tool_usage_table.add_row(tool_type, str(count))
        console.print(tool_usage_table)

        console.print("\n[bold]Tool Call Outcome Summary (Aggregated for each Action Type):[/bold]")
        outcome_details_table = Table(title="Tool Call Outcome Details by Action Type")
        outcome_details_table.add_column("Tool Action Type", style="cyan", overflow="fold")
        outcome_details_table.add_column("Success", style="green", justify="right")
        outcome_details_table.add_column("Error/Reject", style="red", justify="right")
        outcome_details_table.add_column("Cancelled by User", style="yellow", justify="right")
        outcome_details_table.add_column("Other/Unknown", style="dim", justify="right")

        for tool_type, outcomes_map in sorted(tool_call_outcomes.items()):
            outcome_details_table.add_row(
                tool_type,
                str(outcomes_map.get("success",0)),
                str(outcomes_map.get("error_or_rejection",0)),
                str(outcomes_map.get("cancelled_by_user",0)),
                str(outcomes_map.get("other_or_unknown",0))
            )
        console.print(outcome_details_table)
    else:
        console.print("[yellow]No individual tool calls found in the analyzed log entries.[/yellow]")

    # Print example formatted training prompts
    if num_examples_to_print > 0 and interactions_to_analyze:
        console.print(f"\n[bold underline]Random Formatted Training Examples (from N={num_examples_to_print} random log entries from analyzed set):[/bold underline]")

        actual_num_log_entries_to_sample = min(num_examples_to_print, len(interactions_to_analyze))
        selected_log_entries_for_examples = random.sample(interactions_to_analyze, actual_num_log_entries_to_sample)

        total_examples_shown = 0
        max_examples_to_actually_print = 10 # Limit total formatted examples printed to console regardless of N

        for i, log_entry_obj in enumerate(selected_log_entries_for_examples):
            if total_examples_shown >= max_examples_to_actually_print:
                console.print(f"[dim]... (max {max_examples_to_actually_print} formatted examples shown for brevity) ...[/dim]")
                break

            console.print(f"\n--- Log Entry {i+1} (Original Turn ID: {log_entry_obj.get('turn_id', 'N/A')}) ---")
            # Use the EOS token from the actual tokenizer if available, otherwise a placeholder for display
            formatted_prompts_list_for_this_entry = format_interaction_for_training(log_entry_obj, tokenizer_eos_for_examples)

            if formatted_prompts_list_for_this_entry:
                for j, formatted_prompt_str in enumerate(formatted_prompts_list_for_this_entry):
                    if total_examples_shown >= max_examples_to_actually_print: break
                    total_examples_shown += 1
                    console.print(f"  -- Formatted Example {j+1} (from log entry {i+1}) --")
                    # Use Rich Text for better display of newlines and potential special chars
                    console.print(Text(formatted_prompt_str, overflow="fold"))
            else:
                console.print(f"  (No training examples could be generated for this log entry based on current formatting logic)")
        console.print("\n--- End of Formatted Examples ---")

def main():
    """Main execution function for the adaptive training script."""
    args = parse_arguments()

    # --- Analysis Mode ---
    if args.analyze_jsonl_logs is not None:
        console.print(f"[bold cyan]--- JSONL Log Analysis Mode ---[/bold cyan]")
        raw_logs = load_raw_interaction_logs(args.jsonl_log_path)
        if not raw_logs:
            console.print("[error]No logs loaded or logs are empty. Exiting analysis.[/error]")
            return

        # Determine number of examples to show. If --analyze_jsonl_logs is given with no number, default to 5.
        num_examples_to_show_in_analysis = args.analyze_jsonl_logs if args.analyze_jsonl_logs != -1 else 5

        example_eos_token_for_display = "<|EOS|>" # Placeholder if tokenizer fails
        if num_examples_to_show_in_analysis > 0: # Only load tokenizer if we need to show examples
            try:
                # Attempt to load tokenizer just for its EOS token for example display
                # This avoids loading the full model if only analyzing.
                tokenizer_for_examples_display = AutoTokenizer.from_pretrained(args.model_path, trust_remote_code=True)
                if tokenizer_for_examples_display.eos_token:
                    example_eos_token_for_display = tokenizer_for_examples_display.eos_token
            except Exception as e:
                console.print(f"[warning]Could not load tokenizer from '{args.model_path}' to get EOS token for examples: {e}. Using placeholder '{example_eos_token_for_display}'.[/warning]")

        # Pass full args to analysis function so it can use filtering options if provided by user
        analyze_and_print_stats(raw_logs, num_examples_to_show_in_analysis, example_eos_token_for_display, args_for_filtering=args)
        console.print("[info]Log analysis complete. No training performed in this mode.[/info]")
        return

    # --- Training Mode ---
    console.print("[bold blue]Starting Adaptive Model Fine-Tuning Script...[/bold blue]")
    console.print(f"[info]Run configuration: {vars(args)}[/info]") # Log all args

    # Load Tokenizer and Model
    console.print(f"[info]Loading base model and tokenizer from: {args.model_path}[/info]")

    # Quantization config for QLoRA
    bnb_quantization_config = None
    if args.use_qlora:
        console.print("[info]QLoRA enabled: Preparing 4-bit quantization configuration (BitsAndBytesConfig).[/info]")
        bnb_quantization_config = BitsAndBytesConfig(
            load_in_4bit=True,
            bnb_4bit_use_double_quant=True, # Improves quality slightly
            bnb_4bit_quant_type="nf4",      # Recommended quant type for QLoRA
            bnb_4bit_compute_dtype=torch.bfloat16 # Use bfloat16 for computation if available
        )
        console.print("[info]Using QLoRA with NF4 quantization and bfloat16 compute type.[/info]")
        if not torch.cuda.is_available() or not torch.cuda.get_device_capability()[0] >= 8:
             console.print("[warning]QLoRA is most effective on GPUs with bfloat16 support (Ampere architecture / CUDA capability >= 8.0). Performance might vary.[/warning]")


    try:
        tokenizer = AutoTokenizer.from_pretrained(args.model_path, trust_remote_code=True)
        # Set pad token if not already set. Common practice is to use EOS token for padding in Causal LMs.
        if tokenizer.pad_token is None:
            tokenizer.pad_token = tokenizer.eos_token
            console.print(f"[info]Tokenizer `pad_token` was None. Set to `eos_token`: '{tokenizer.eos_token}'[/info]")

        # Determine device map for model loading.
        # For QLoRA, device_map="auto" or {"":0} is common to put the quantized model on GPU 0.
        # If not using QLoRA, "auto" is usually fine for multi-GPU or CPU.
        device_map_config = "auto" if not args.use_qlora else {"":0} # Pin QLoRA to GPU 0 by default

        model = AutoModelForCausalLM.from_pretrained(
            args.model_path,
            quantization_config=bnb_quantization_config, # None if not using QLoRA
            device_map=device_map_config, # Handles placing model on devices
            trust_remote_code=True
        )
        console.print("[success]Base model and tokenizer loaded successfully.[/success]")

        if args.use_qlora:
            console.print("[info]Preparing QLoRA model for k-bit training (gradient checkpointing, etc.).[/info]")
            model = prepare_model_for_kbit_training(model)
            console.print("[success]Model prepared for k-bit training (QLoRA).[/success]")

    except Exception as e:
        console.print(f"[error]Fatal error loading base model or tokenizer from '{args.model_path}': {e}[/error]")
        console.print("[info]Ensure the model path is correct and contains valid Hugging Face model files and tokenizer configuration.")
        if args.use_qlora: console.print("[info]If using QLoRA, ensure 'bitsandbytes' is installed correctly for your CUDA version.")
        return # Cannot proceed without model/tokenizer

    # Configure LoRA
    # Parse comma-separated target modules string into a list
    lora_target_modules_list = [module.strip() for module in args.lora_target_modules.split(',') if module.strip()] \
        if args.lora_target_modules else ["q_proj", "v_proj"] # Default if empty or not provided

    console.print(
        f"[info]Configuring LoRA: r={args.lora_r}, alpha={args.lora_alpha}, dropout={args.lora_dropout}. "
        f"Targeting modules: {lora_target_modules_list}"
    )
    peft_lora_config = LoraConfig(
        r=args.lora_r,
        lora_alpha=args.lora_alpha,
        target_modules=lora_target_modules_list,
        lora_dropout=args.lora_dropout,
        bias="none", # Common practice for LoRA
        task_type=TaskType.CAUSAL_LM # Specify task type for Causal Language Modeling
    )

    try:
        # Apply PEFT configuration to the model
        model = get_peft_model(model, peft_lora_config)
        console.print("[success]PEFT (LoRA) model configured successfully.[/success]")
        # Print trainable parameters
        trainable_params, all_params = model.get_nb_trainable_parameters()
        console.print(
            f"[info]Number of trainable LoRA parameters: {trainable_params:,} "
            f"({100 * trainable_params / all_params:.2f}% of total model parameters: {all_params:,})"
        )
    except Exception as e:
        console.print(f"[error]Fatal error configuring PEFT (LoRA) on the model: {e}[/error]")
        console.print("[info]Check if `lora_target_modules` are valid for the loaded model architecture.")
        return

    # Load and prepare dataset
    console.print("[info]Loading, filtering, and tokenizing training dataset from interaction logs...[/info]")
    # prepare_training_dataset now takes the full 'args' object to access filtering options
    train_dataset_tokenized = prepare_training_dataset(args, tokenizer)

    if not train_dataset_tokenized:
        console.print("[error]Failed to prepare training dataset or dataset is empty. Exiting training.[/error]")
        return

    # Data collator for language modeling (handles padding within batches)
    data_collator_for_lm = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False) # mlm=False for Causal LM

    # Configure Training Arguments
    console.print(f"[info]Setting up TrainingArguments. Output directory for checkpoints and logs: {args.output_dir}[/info]")
    os.makedirs(args.output_dir, exist_ok=True) # Ensure output directory exists

    # Determine fp16/bf16 settings
    use_fp16 = not args.use_qlora # QLoRA handles its own precision internally with bnb_4bit_compute_dtype
    use_bf16 = args.use_qlora and torch.cuda.is_available() and torch.cuda.is_bf16_supported()

    if use_fp16: console.print("[info]FP16 training enabled (if not using QLoRA).")
    if use_bf16: console.print("[info]BF16 compute type enabled for QLoRA (if supported by GPU).")


    # RichProgressCallback for better CLI progress display
    # Ensure this is only added if RICH_AVAILABLE to avoid errors.
    trainer_callbacks = [RichProgressCallback()] if RICH_AVAILABLE else []

    huggingface_trainer_args = TrainingArguments(
        output_dir=args.output_dir,
        num_train_epochs=args.num_train_epochs,
        per_device_train_batch_size=args.per_device_train_batch_size,
        gradient_accumulation_steps=args.gradient_accumulation_steps,
        learning_rate=args.learning_rate,

        logging_steps=10,       # How often to log training metrics
        save_strategy="epoch",  # Save checkpoints at the end of each epoch

        fp16=use_fp16,          # Enable mixed precision training if not QLoRA
        bf16=use_bf16,          # Enable bfloat16 if QLoRA and supported

        optim=args.optimizer,
        lr_scheduler_type=args.lr_scheduler_type,
        warmup_steps=args.warmup_steps,
        weight_decay=args.weight_decay,

        disable_tqdm=RICH_AVAILABLE, # Disable default tqdm if Rich progress is used
        logging_dir=f"{args.output_dir}/training_logs", # Subdirectory for TensorBoard/etc. logs
        report_to="none" # Disable reporting to external services like W&B by default
        # Other useful args to consider: save_total_limit, evaluation_strategy, eval_steps, load_best_model_at_end
    )

    # Initialize Trainer
    trainer = Trainer(
        model=model,
        args=huggingface_trainer_args,
        train_dataset=train_dataset_tokenized,
        data_collator=data_collator_for_lm,
        callbacks=trainer_callbacks
    )

    console.print("[bold green]Starting model training...[/bold green]")
    try:
        training_result = trainer.train()
        console.print(f"[success]Training completed successfully.[/success]")
        if hasattr(training_result, 'metrics') and training_result.metrics:
            console.print(f"Training metrics: {training_result.metrics}")
    except Exception as e:
        console.print(f"[error]An error occurred during the training process: {e}[/error]")
        console.print_exception(show_locals=True) # Print full traceback for debugging
        console.print("[info]Training may have been interrupted. Partial results might be saved if save_strategy was triggered.")
        return # Exit if training fails critically

    # Save the trained PEFT adapters and tokenizer
    console.print(f"[info]Saving trained PEFT adapters and tokenizer configuration to: {args.output_dir}[/info]")
    try:
        # save_model will save the PEFT adapter configuration and weights.
        # For a full model save (merged), one would need to merge adapters first.
        trainer.save_model(args.output_dir)
        # Save the tokenizer so it can be loaded with the fine-tuned model/adapters
        tokenizer.save_pretrained(args.output_dir)
        console.print(f"[success]PEFT adapters and tokenizer saved successfully to '{args.output_dir}'.[/success]")
        console.print(f"[info]To use these adapters, load the base model and then apply PeftModel.from_pretrained(base_model, '{args.output_dir}').")
        console.print(f"[info]Alternatively, merge them into the base model using a separate script (see merge_adapters.py example in README).")
    except Exception as e:
        console.print(f"[error]Error saving PEFT adapters or tokenizer: {e}[/error]")

    console.print("[bold blue]Adaptive fine-tuning script finished.[/bold blue]")

if __name__ == "__main__":
    main()
    parser.add_argument("--jsonl_log_path", type=str, default=str(Path(__file__).resolve().parent / ".agi_terminal_cache" / "interaction_logs.jsonl"), help="Path to JSONL interaction log file.")
    parser.add_argument("--output_dir", type=str, default=DEFAULT_OUTPUT_DIR, help="Directory for PEFT adapters.")
    parser.add_argument("--num_train_epochs", type=int, default=1)
    parser.add_argument("--per_device_train_batch_size", type=int, default=1)
    parser.add_argument("--gradient_accumulation_steps", type=int, default=4)
    parser.add_argument("--learning_rate", type=float, default=2e-4)
    parser.add_argument("--lora_r", type=int, default=16)
    parser.add_argument("--lora_alpha", type=int, default=32)
    parser.add_argument("--lora_dropout", type=float, default=0.05)
    parser.add_argument("--max_seq_length", type=int, default=1024)
    parser.add_argument("--use_qlora", action="store_true", help="Enable QLoRA (4-bit quantization).")
    parser.add_argument("--lora_target_modules", type=str, default="q_proj,v_proj,k_proj,o_proj,gate_proj,up_proj,down_proj", help="Comma-separated LoRA target modules.")
    parser.add_argument("--optimizer", type=str, default="adamw_torch")
    parser.add_argument("--lr_scheduler_type", type=str, default="linear")
    parser.add_argument("--warmup_steps", type=int, default=0)
    parser.add_argument("--weight_decay", type=float, default=0.0)

    # New CLI arguments for selective training data strategies
    parser.add_argument("--train-on-successful-tool-use", type=str, default=None, metavar="TOOL_NAME|all", help="Filter for successful tool use (specific tool or 'all').")
    parser.add_argument("--train-on-failed-tool-use", type=str, default=None, metavar="TOOL_NAME|all", help="Filter for failed/cancelled tool use (specific tool or 'all').")
    parser.add_argument("--train-on-successful-plans", action="store_true", help="Filter for successfully completed multi-step plans.")
    parser.add_argument("--train-on-halted-plans", action="store_true", help="Filter for halted multi-step plans.")
    parser.add_argument("--min-tool-interactions", type=int, default=0, metavar="N", help="Filter for turns with at least N tool interactions.")

    return parser.parse_args()

def format_context_for_prompt(context_dict: dict) -> str:
    if not context_dict: return "SYSTEM_CONTEXT: None"
    parts = []
    if "cwd" in context_dict: parts.append(f"CWD: {context_dict['cwd']}")
    if "project_root" in context_dict: parts.append(f"ProjectRoot: {context_dict['project_root']}")
    git_info = context_dict.get("git_info", {})
    if git_info.get("in_git_repo"):
        branch = git_info.get('branch', 'N/A')
        modified_files = git_info.get('modified_files', 0)
        status_str = f"{modified_files} modified" if modified_files > 0 else "Clean"
        parts.append(f"Git: Branch='{branch}', Status='{status_str}'")
    file_counts = context_dict.get("file_type_counts", {})
    if file_counts:
        top_files = sorted(file_counts.items(), key=lambda item: item[1], reverse=True)[:3]
        files_str = ", ".join([f"{lang}:{count}" for lang, count in top_files])
        parts.append(f"FileTypes: {files_str}{'...' if len(file_counts) > 3 else ''}")
    key_snippets_headers = context_dict.get("key_file_snippets", [])
    if key_snippets_headers:
        filenames = []
        for header_text in key_snippets_headers:
            match = re.search(r"--- Snippet from ([\w\.\-]+)", header_text)
            if match: filenames.append(match.group(1))
        if filenames: parts.append(f"KeyFilesProvided: [{', '.join(filenames)}]")
    return "SYSTEM_CONTEXT:\n" + "\n".join(f"  {p}" for p in parts) if parts else "SYSTEM_CONTEXT: (No specific context details available)"

def format_tool_interactions_for_prompt(tool_interactions: list, max_outcome_chars: int = 200) -> str:
    if not tool_interactions: return ""
    dialogue = ["\nINTERMEDIATE_STEPS:"]
    for i, tool_call in enumerate(tool_interactions):
        action_type = tool_call.get('action_type', 'unknown_action')
        action_details = tool_call.get('action_details', {})
        reasoning = tool_call.get('reasoning', 'No reasoning.')
        outcome_summary = tool_call.get('tool_outcome_summary', 'No outcome summary.')
        agi_secondary_response = tool_call.get('agi_secondary_raw_response')
        dialogue.append(f"  --- TOOL_CALL_ATTEMPT_{i+1} ---")
        dialogue.append(f"    AGI_REQUESTED_ACTION: {action_type}")
        details_str = json.dumps(action_details);
        if len(details_str) > 150: details_str = details_str[:150] + "..."
        dialogue.append(f"    ACTION_DETAILS: {details_str}")
        dialogue.append(f"    AGI_REASONING: {reasoning}")
        outcome_display = outcome_summary
        if len(outcome_display) > max_outcome_chars: outcome_display = outcome_display[:max_outcome_chars] + f"..."
        dialogue.append(f"    SYSTEM_OUTCOME: {outcome_display}")
        if agi_secondary_response:
            secondary_resp_display = agi_secondary_response
            if len(secondary_resp_display) > max_outcome_chars * 2: secondary_resp_display = secondary_resp_display[:max_outcome_chars*2] + f"..."
            dialogue.append(f"    AGI_RESPONSE_TO_OUTCOME: {secondary_resp_display}")
    return "\n".join(dialogue)

def _format_for_direct_answer(entry: dict, eos_token: str) -> Optional[str]:
    user_query = entry.get("user_query", ""); agi_final_response = entry.get("agi_final_response_to_user", ""); context_dict = entry.get("context_at_query_time", {})
    if not user_query or not agi_final_response: return None
    context_str = format_context_for_prompt(context_dict)
    return f"{context_str}\nUSER: {user_query}\nASSISTANT: {agi_final_response}{eos_token}"

def _format_for_single_tool_call_generation(entry: dict, eos_token: str) -> Optional[str]:
    user_query = entry.get("user_query", ""); agi_initial_raw_response = entry.get("agi_initial_raw_response", ""); context_dict = entry.get("context_at_query_time", {})
    if not user_query or not agi_initial_raw_response or not (agi_initial_raw_response.strip().startswith("{") and agi_initial_raw_response.strip().endswith("}")): return None
    try:
        parsed_json = json.loads(agi_initial_raw_response)
        if not isinstance(parsed_json, dict) or not parsed_json.get("action") or parsed_json.get("action") == "execute_plan": return None
    except json.JSONDecodeError: return None
    context_str = format_context_for_prompt(context_dict)
    system_instruction = "SYSTEM_INSTRUCTION: You have access to tools. Respond with a JSON action or a direct answer."
    return f"{context_str}\nUSER: {user_query}\n{system_instruction}\nASSISTANT: {agi_initial_raw_response.strip()}{eos_token}"

def _format_for_tool_outcome_processing(entry: dict, tool_interaction: dict, eos_token: str) -> Optional[str]:
    user_query = entry.get("user_query", ""); context_dict = entry.get("context_at_query_time", {}); agi_secondary_response = tool_interaction.get("agi_secondary_raw_response")
    if not user_query or not agi_secondary_response or not context_dict: return None
    context_str = format_context_for_prompt(context_dict); tool_summary_str = format_tool_interactions_for_prompt([tool_interaction])
    system_instruction = "SYSTEM_INSTRUCTION: Based on the tool outcome, respond to the user's original query."
    return f"{context_str}\nUSER: {user_query}{tool_summary_str}\n{system_instruction}\nASSISTANT: {agi_secondary_response}{eos_token}"

def _format_for_plan_generation(entry: dict, eos_token: str) -> Optional[str]:
    user_query = entry.get("user_query", ""); agi_initial_raw_response = entry.get("agi_initial_raw_response", ""); context_dict = entry.get("context_at_query_time", {})
    if not user_query or not agi_initial_raw_response: return None
    try:
        parsed_json = json.loads(agi_initial_raw_response)
        if not isinstance(parsed_json, dict) or parsed_json.get("action") != "execute_plan": return None
    except json.JSONDecodeError: return None
    context_str = format_context_for_prompt(context_dict)
    system_instruction = "SYSTEM_INSTRUCTION: For multi-step tasks, use 'execute_plan'."
    return f"{context_str}\nUSER: {user_query}\n{system_instruction}\nASSISTANT: {agi_initial_raw_response.strip()}{eos_token}"

def _format_for_plan_summary(entry: dict, eos_token: str) -> Optional[str]:
    user_query = entry.get("user_query", ""); context_dict = entry.get("context_at_query_time", {}); plan_details = entry.get("plan_execution_details", {})
    agi_initial_plan_json = entry.get("agi_initial_raw_response", ""); final_response_after_plan = plan_details.get("agi_final_response_after_plan")
    if not all([user_query, context_dict, plan_details, final_response_after_plan, agi_initial_plan_json]): return None
    context_str = format_context_for_prompt(context_dict); plan_step_outcomes = []
    for ti in entry.get("tool_interactions", []):
        if ti.get("part_of_plan_step") is not None:
            action = ti.get('action_type', 'unknown'); outcome = ti.get('tool_outcome_summary', 'No outcome.')[:150] + ("..." if len(ti.get('tool_outcome_summary', '')) > 150 else "")
            plan_step_outcomes.append(f"  - Step {ti['part_of_plan_step']+1} ({action}): {outcome}")
    plan_execution_summary_str = "PLAN_EXECUTION_SUMMARY:\n" + "\n".join(plan_step_outcomes) if plan_step_outcomes else "PLAN_EXECUTION_SUMMARY: No step outcomes."
    proposed_plan_str = f"PROPOSED_PLAN_JSON:\n{agi_initial_plan_json.strip()}"
    system_instruction = "SYSTEM_INSTRUCTION: Summarize plan execution and respond to user."
    return f"{context_str}\nUSER: {user_query}\n{proposed_plan_str}\n{plan_execution_summary_str}\n{system_instruction}\nASSISTANT: {final_response_after_plan}{eos_token}"

def format_interaction_for_training(interaction_entry: dict, tokenizer_eos_token: str) -> list[str]:
    training_examples = []; user_query = interaction_entry.get("user_query"); agi_final_response = interaction_entry.get("agi_final_response_to_user")
    if not user_query or not agi_final_response: return []
    is_plan = "plan_execution_details" in interaction_entry and interaction_entry["plan_execution_details"].get("action_type") == "execute_plan"
    tool_interactions = interaction_entry.get("tool_interactions", [])
    agi_initial_raw_is_json = interaction_entry.get("agi_initial_raw_response", "").strip().startswith("{")
    if is_plan:
        ex_plan_gen = _format_for_plan_generation(interaction_entry, tokenizer_eos_token)
        if ex_plan_gen: training_examples.append(ex_plan_gen)
        ex_plan_sum = _format_for_plan_summary(interaction_entry, tokenizer_eos_token)
        if ex_plan_sum: training_examples.append(ex_plan_sum)
    elif tool_interactions:
        if agi_initial_raw_is_json:
            ex_single_tool_gen = _format_for_single_tool_call_generation(interaction_entry, tokenizer_eos_token)
            if ex_single_tool_gen: training_examples.append(ex_single_tool_gen)
        if tool_interactions[0].get("agi_secondary_raw_response"):
            ex_tool_outcome_proc = _format_for_tool_outcome_processing(interaction_entry, tool_interactions[0], tokenizer_eos_token)
            if ex_tool_outcome_proc: training_examples.append(ex_tool_outcome_proc)
        elif not training_examples:
            ex_direct = _format_for_direct_answer(interaction_entry, tokenizer_eos_token)
            if ex_direct: training_examples.append(ex_direct)
    else:
        ex_direct = _format_for_direct_answer(interaction_entry, tokenizer_eos_token)
        if ex_direct: training_examples.append(ex_direct)
    return training_examples

def load_raw_interaction_logs(jsonl_log_path: str) -> list[dict]:
    raw_interactions = []; log_file = Path(jsonl_log_path)
    if not log_file.exists(): console.print(f"[yellow]JSONL log file not found: {jsonl_log_path}.[/yellow]"); return []
    console.print(f"[info]Processing JSONL: {jsonl_log_path}...[/info]")
    try:
        with open(log_file, 'r', encoding='utf-8') as f:
            for line_num, line in enumerate(f):
                try: raw_interactions.append(json.loads(line))
                except json.JSONDecodeError as e: console.print(f"[yellow]Skipping malformed JSON line {line_num + 1}: {e}[/yellow]")
    except Exception as e: console.print(f"[error]Error reading {jsonl_log_path}: {e}[/error]"); return []
    if not raw_interactions: console.print(f"[yellow]No valid interactions in {jsonl_log_path}.[/yellow]")
    return raw_interactions

def _is_tool_call_successful(tool_call: dict) -> bool:
    user_confirmation = tool_call.get("user_confirmation", "").lower()
    if user_confirmation in ["cancelled", "denied_by_system_whitelist", "n/a_malformed_request", "denied_by_system_static_analysis"]: return False
    outcome_summary = tool_call.get("tool_outcome_summary", "").lower()
    if any(err_kw in outcome_summary for err_kw in ["error:", "failed", "malformed", "exception:"]): return False
    if any(succ_kw in outcome_summary for succ_kw in ["success", "processed", "executed", "identical", "up-to-date", "no output", "nothing to commit", "provided to agi"]): return True
    if tool_call.get("action_type") == "execute_python_code" and "exception:" not in outcome_summary: return True # Assumed success if no exception & not cancelled
    return False

def filter_raw_interactions(raw_interactions: list[dict], args: argparse.Namespace) -> list[dict]:
    if not any([args.train_on_successful_tool_use, args.train_on_failed_tool_use, args.train_on_successful_plans, args.train_on_halted_plans, args.min_tool_interactions > 0]):
        return raw_interactions
    filtered_interactions = []
    console.print("[info]Applying training data filters...")
    for entry in raw_interactions:
        passes_filter = True
        is_plan_turn = "plan_execution_details" in entry
        plan_details = entry.get("plan_execution_details", {})

        if args.train_on_successful_plans:
            if not (is_plan_turn and "Halted" not in plan_details.get("plan_outcome", "")): passes_filter = False
        if args.train_on_halted_plans and passes_filter:
            if not (is_plan_turn and "Halted" in plan_details.get("plan_outcome", "")): passes_filter = False

        num_tool_interactions = len(entry.get("tool_interactions", []))
        if args.min_tool_interactions > 0 and num_tool_interactions < args.min_tool_interactions: passes_filter = False

        if passes_filter and (args.train_on_successful_tool_use or args.train_on_failed_tool_use):
            tool_match_found = False
            for tool_call in entry.get("tool_interactions", []):
                tool_action = tool_call.get("action_type")
                is_successful = _is_tool_call_successful(tool_call)
                if args.train_on_successful_tool_use and is_successful and \
                   (args.train_on_successful_tool_use == "all" or args.train_on_successful_tool_use == tool_action):
                    tool_match_found = True; break
                if args.train_on_failed_tool_use and not is_successful and \
                   (args.train_on_failed_tool_use == "all" or args.train_on_failed_tool_use == tool_action):
                    tool_match_found = True; break
            if not tool_match_found: passes_filter = False

        if passes_filter: filtered_interactions.append(entry)
    console.print(f"[info]Retained {len(filtered_interactions)} interactions after filtering (out of {len(raw_interactions)}).")
    return filtered_interactions

def prepare_training_dataset(args: argparse.Namespace, tokenizer: AutoTokenizer) -> list[dict]:
    raw_interactions = load_raw_interaction_logs(args.jsonl_log_path)
    if not raw_interactions: return []
    filtered_interactions = filter_raw_interactions(raw_interactions, args)
    if not filtered_interactions: console.print("[yellow]No interactions after filtering.[/yellow]"); return []
    all_formatted_texts = []
    console.print(f"[info]Formatting {len(filtered_interactions)} filtered interactions...[/info]")
    # ... (progress bar logic as before) ...
    for entry in filtered_interactions:
        formatted_texts_for_entry = format_interaction_for_training(entry, tokenizer.eos_token)
        if formatted_texts_for_entry: all_formatted_texts.extend(formatted_texts_for_entry)
    # ... (progress bar stop, checks for min_dataset_size, tokenization as before) ...
    if not all_formatted_texts: console.print("[yellow]No examples generated from filtered logs.[/yellow]"); return []
    min_examples = 5
    if len(all_formatted_texts) < min_examples:
        console.print(f"[warning]Number of examples ({len(all_formatted_texts)}) is < {min_examples}. Training might be ineffective.[/warning]")
        if input(f"Continue with {len(all_formatted_texts)} examples? (yes/NO): ").lower() != "yes":
            console.print("[info]Training aborted.[/info]"); return []
    console.print(f"[success]Generated {len(all_formatted_texts)} training examples.[/success]")
    tokenized_dataset = []
    # ... (tokenization loop as before) ...
    for text in all_formatted_texts:
        tokenized_input = tokenizer(text, truncation=True, max_length=args.max_seq_length, padding="max_length")
        tokenized_dataset.append({"input_ids": tokenized_input["input_ids"], "attention_mask": tokenized_input["attention_mask"], "labels": tokenized_input["input_ids"].copy()})
    console.print(f"[success]Tokenized {len(tokenized_dataset)} examples.[/success]")
    return tokenized_dataset

def analyze_and_print_stats(raw_interactions: list[dict], num_examples_to_print: int, tokenizer_eos_for_examples: str, args_for_filtering: Optional[argparse.Namespace] = None):
    if not raw_interactions: console.print("[yellow]No interactions to analyze.[/yellow]"); return

    interactions_to_analyze = raw_interactions
    if args_for_filtering: # If CLI args provided, filter before analyzing (to see effect of filters)
        console.print("[info]Analyzing logs based on provided filter arguments...")
        interactions_to_analyze = filter_raw_interactions(raw_interactions, args_for_filtering)
        if not interactions_to_analyze:
            console.print("[yellow]No interactions remain after filtering for analysis. Original stats will be shown if different.[/yellow]")
            # Optionally, one could fall back to showing stats for raw_interactions or just stop.
            # For now, let's indicate that filtering resulted in zero.
            # To show original stats if filtered is empty:
            # if not interactions_to_analyze and raw_interactions is not interactions_to_analyze:
            #     console.print("[info]Showing stats for UNFILTERED logs as filtered set is empty.")
            #     interactions_to_analyze = raw_interactions # Fallback
            # else:
            #     return # If already analyzing raw and it's empty, or filtered is empty and we don't want to fallback
            if not interactions_to_analyze: return


    total_turns = len(interactions_to_analyze); turns_with_tools = 0; tool_type_counts = {}; tool_outcomes = {}
    total_user_query_len = 0; total_agi_response_len = 0; plan_turns = 0; successful_plans = 0; halted_plans = 0

    for entry in interactions_to_analyze: # Use the (potentially filtered) list
        total_user_query_len += len(entry.get("user_query", ""))
        total_agi_response_len += len(entry.get("agi_final_response_to_user", ""))
        if entry.get("plan_execution_details"):
            plan_turns +=1
            if "Halted" not in entry["plan_execution_details"].get("plan_outcome", "") and \
               "Malformed" not in entry["plan_execution_details"].get("plan_outcome", ""): # Count successful/completed
                successful_plans +=1
            elif "Halted" in entry["plan_execution_details"].get("plan_outcome", ""):
                halted_plans +=1
        tool_interactions_list = entry.get("tool_interactions", [])
        if tool_interactions_list:
            turns_with_tools += 1
            for tool_call in tool_interactions_list:
                action = tool_call.get("action_type", "unknown_action")
                tool_type_counts[action] = tool_type_counts.get(action, 0) + 1
                if action not in tool_outcomes: tool_outcomes[action] = {"success": 0, "error": 0, "cancelled": 0, "other": 0}

                # Use _is_tool_call_successful for more robust outcome checking
                if _is_tool_call_successful(tool_call):
                    tool_outcomes[action]["success"] += 1
                elif tool_call.get("user_confirmation", "").lower() == "cancelled":
                    tool_outcomes[action]["cancelled"] +=1
                elif any(err_kw in tool_call.get("tool_outcome_summary", "").lower() for err_kw in ["error:", "failed", "malformed", "exception:"]) or \
                     tool_call.get("user_confirmation", "").lower() in ["denied_by_system_whitelist", "n/a_malformed_request", "denied_by_system_static_analysis"]:
                    tool_outcomes[action]["error"] += 1
                else: tool_outcomes[action]["other"] += 1

    console.print(f"\n[bold underline]Interaction Log Analysis (Analyzed {total_turns} entries)[/bold underline]")
    # ... (rest of the stats printing as before, using the potentially filtered counts) ...
    console.print(f"Total Interaction Turns Analyzed: {total_turns}")
    console.print(f"Turns with any Tool Use: {turns_with_tools} ({turns_with_tools/total_turns:.1%} if total_turns > 0 else 0.0)%)")
    console.print(f"Turns involving a Plan: {plan_turns} ({plan_turns/total_turns:.1%} if total_turns > 0 else 0.0)%)")
    if plan_turns > 0 : console.print(f"  Successful/Completed Plans: {successful_plans}")
    if plan_turns > 0 : console.print(f"  Halted Plans: {halted_plans}")
    avg_user_query_len = total_user_query_len / total_turns if total_turns > 0 else 0
    avg_agi_response_len = total_agi_response_len / total_turns if total_turns > 0 else 0
    console.print(f"Average User Query Length: {avg_user_query_len:.0f} chars")
    console.print(f"Average AGI Final Response Length: {avg_agi_response_len:.0f} chars")
    if tool_type_counts:
        console.print("\n[bold]Tool Usage Breakdown (individual calls):[/bold]")
        # ... (tool_table printing as before) ...
        tool_table = Table(title="Tool Call Counts"); tool_table.add_column("Tool Action", style="cyan"); tool_table.add_column("Count", style="magenta", justify="right")
        for tool, count in sorted(tool_type_counts.items()): tool_table.add_row(tool, str(count))
        console.print(tool_table)
        console.print("\n[bold]Tool Outcome Summary (individual calls):[/bold]")
        outcome_table = Table(title="Tool Call Outcome Details"); outcome_table.add_column("Tool Action", style="cyan"); outcome_table.add_column("Success", style="green", justify="right"); outcome_table.add_column("Error/Reject", style="red", justify="right"); outcome_table.add_column("Cancelled", style="yellow", justify="right"); outcome_table.add_column("Other/Unknown", style="dim", justify="right")
        for tool, outcomes_map in sorted(tool_outcomes.items()): outcome_table.add_row(tool, str(outcomes_map.get("success",0)), str(outcomes_map.get("error",0)), str(outcomes_map.get("cancelled",0)), str(outcomes_map.get("other",0)))
        console.print(outcome_table)

    else: console.print("No individual tool calls found in analyzed logs.")

    if num_examples_to_print > 0 and interactions_to_analyze:
        console.print(f"\n[bold underline]Random Formatted Training Examples (N={num_examples_to_print} original log entries from analyzed set):[/bold underline]")
        actual_num_to_print = min(num_examples_to_print, len(interactions_to_analyze))
        selected_log_entries = random.sample(interactions_to_analyze, actual_num_to_print)
        example_count = 0
        for i, entry in enumerate(selected_log_entries):
            console.print(f"\n--- Log Entry {i+1} (Original Turn ID: {entry.get('turn_id', 'N/A')}) ---")
            formatted_prompts_for_entry = format_interaction_for_training(entry, tokenizer_eos_for_examples)
            if formatted_prompts_for_entry:
                for j, formatted_prompt in enumerate(formatted_prompts_for_entry):
                    example_count += 1
                    console.print(f"  -- Example {example_count} (from log entry {i+1}, sub-example {j+1}) --")
                    console.print(Text(formatted_prompt, overflow="fold"))
            else: console.print(f"  (No training examples generated for this log entry)")
        console.print("\n--- End of Examples ---")

def main():
    args = parse_arguments()
    if args.analyze_jsonl_logs is not None:
        console.print(f"[bold cyan]--- JSONL Log Analysis Mode ---[/bold cyan]")
        raw_logs = load_raw_interaction_logs(args.jsonl_log_path)
        if not raw_logs: console.print("[error]No logs loaded. Exiting.[/error]"); return
        num_examples_to_show = args.analyze_jsonl_logs if args.analyze_jsonl_logs != -1 else 5
        example_eos_token = "<|eos|>"
        if num_examples_to_show > 0:
            try:
                tokenizer_for_examples = AutoTokenizer.from_pretrained(args.model_path, trust_remote_code=True)
                if tokenizer_for_examples.eos_token: example_eos_token = tokenizer_for_examples.eos_token
            except Exception as e: console.print(f"[warning]Could not load tokenizer from '{args.model_path}' for examples: {e}.[/warning]")
        analyze_and_print_stats(raw_logs, num_examples_to_show, example_eos_token, args) # Pass args for filtering in analysis
        console.print("[info]Log analysis complete.[/info]"); return

    console.print("[bold blue]Starting Adaptive Training Script...[/bold blue]")
    # ... (rest of main training logic as before, but prepare_training_dataset now takes args) ...
    console.print(f"[info]Configuration: {args}[/info]")
    console.print(f"[info]Loading base model from: {args.model_path}[/info]")
    bnb_config = BitsAndBytesConfig(load_in_4bit=True, bnb_4bit_use_double_quant=True, bnb_4bit_quant_type="nf4", bnb_4bit_compute_dtype=torch.bfloat16) if args.use_qlora else None
    if args.use_qlora: console.print("[info]QLoRA enabled (4-bit).[/info]")
    try:
        tokenizer = AutoTokenizer.from_pretrained(args.model_path, trust_remote_code=True)
        if tokenizer.pad_token is None: tokenizer.pad_token = tokenizer.eos_token; console.print(f"[info]Set pad_token to eos_token ({tokenizer.eos_token})[/info]")
        model = AutoModelForCausalLM.from_pretrained(args.model_path, quantization_config=bnb_config, device_map={"":0}, trust_remote_code=True)
        console.print("[success]Tokenizer and model loaded.[/success]")
        if args.use_qlora: model = prepare_model_for_kbit_training(model); console.print("[info]Prepared model for k-bit training.[/info]")
    except Exception as e: console.print(f"[error]Error loading model/tokenizer: {e}[/error]"); return

    parsed_target_modules = [m.strip() for m in args.lora_target_modules.split(',') if m.strip()] if args.lora_target_modules else ["q_proj", "v_proj"]
    console.print(f"[info]LoRA (r={args.lora_r}, alpha={args.lora_alpha}, dropout={args.lora_dropout}) for modules: {parsed_target_modules}[/info]")
    lora_config = LoraConfig(r=args.lora_r, lora_alpha=args.lora_alpha, target_modules=parsed_target_modules, lora_dropout=args.lora_dropout, bias="none", task_type=TaskType.CAUSAL_LM)
    try:
        model = get_peft_model(model, lora_config); console.print("[success]PEFT model configured.[/success]")
        trainable_params, all_param = model.get_nb_trainable_parameters(); console.print(f"[info]Trainable LoRA params: {trainable_params} ({100 * trainable_params / all_param:.2f}% of total)[/info]")
    except Exception as e: console.print(f"[error]Error configuring PEFT: {e}[/error]"); return

    console.print("[info]Loading and preparing dataset...[/info]")
    train_dataset = prepare_training_dataset(args, tokenizer) # Pass full args object
    if not train_dataset: console.print("[info]No training data. Exiting.[/info]"); return

    data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)
    console.print(f"[info]Training arguments. Output dir: {args.output_dir}[/info]")
    os.makedirs(args.output_dir, exist_ok=True)

    class RichProgressCallback(transformers.TrainerCallback):
        def __init__(self): super().__init__(); self.progress = None; self.train_task_id = None
        def on_train_begin(self, args, state, control, **kwargs):
            if RICH_AVAILABLE and state.is_world_process_zero:
                self.progress = Progress(TextColumn("{task.description}"), BarColumn(), TextColumn("{task.percentage:>3.1f}%"), TextColumn("Steps: {task.completed}/{task.total}"), TimeRemainingColumn(), TimeElapsedColumn(), console=console, transient=True)
                self.progress.start(); self.train_task_id = self.progress.add_task("Training", total=state.max_steps)
        def on_step_end(self, args, state, control, **kwargs):
            if RICH_AVAILABLE and state.is_world_process_zero and self.progress: self.progress.update(self.train_task_id, advance=1)
        def on_train_end(self, args, state, control, **kwargs):
            if RICH_AVAILABLE and state.is_world_process_zero and self.progress: self.progress.stop()
    callbacks = [RichProgressCallback()] if RICH_AVAILABLE else []

    training_args = TrainingArguments(
        output_dir=args.output_dir, num_train_epochs=args.num_train_epochs, per_device_train_batch_size=args.per_device_train_batch_size,
        gradient_accumulation_steps=args.gradient_accumulation_steps, learning_rate=args.learning_rate, logging_steps=10, save_strategy="epoch",
        fp16=not args.use_qlora, bf16=args.use_qlora and torch.cuda.is_bf16_supported(), optim=args.optimizer,
        lr_scheduler_type=args.lr_scheduler_type, warmup_steps=args.warmup_steps, weight_decay=args.weight_decay,
        disable_tqdm=RICH_AVAILABLE, logging_dir=f"{args.output_dir}/logs", report_to="none"
    )
    trainer = Trainer(model=model, args=training_args, train_dataset=train_dataset, data_collator=data_collator, callbacks=callbacks)
    console.print("[bold green]Starting training...[/bold green]")
    try:
        train_result = trainer.train(); console.print(f"[success]Training completed. Metrics: {train_result.metrics}[/success]")
    except Exception as e: console.print(f"[error]Error during trainer.train(): {e}[/error]")
    console.print(f"[info]Saving PEFT adapters to {args.output_dir}...[/info]")
    try:
        trainer.save_model(args.output_dir); tokenizer.save_pretrained(args.output_dir)
        console.print(f"[success]Adapters and tokenizer saved to {args.output_dir}.[/success]")
    except Exception as e: console.print(f"[error]Error saving model/adapters: {e}[/error]")
    console.print("[bold blue]Adaptive training script finished.[/bold blue]")

if __name__ == "__main__":
    main()
